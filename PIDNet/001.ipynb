{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-23 20:14:55.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload_weights_start\u001b[0m\n",
      "\u001b[32m2024-05-23 20:14:55.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mLoaded 453 parameters!\u001b[0m\n",
      "\u001b[32m2024-05-23 20:14:55.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mload_weights_done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "\n",
    "from loguru import logger\n",
    "import models\n",
    "\n",
    "# FILE_PATH = 'samples/daejeon1_000000_000001_leftImg8bit.png'\n",
    "# FILE_PATH = 'samples/test.mp4'\n",
    "FILE_PATH = 'samples/0001TP_009210.png'\n",
    "FILE_NAME = os.path.basename(FILE_PATH)\n",
    "SAVE_DIR = 'output/'\n",
    "FONTSCALE = 1\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "THICKNESS = 2\n",
    "BLUE_COLOR = (0,0,255)\n",
    "RED_COLOR = (255,40,40)\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "color_map = [(128, 64,128),\n",
    "             (244, 35,232),\n",
    "             ( 70, 70, 70),\n",
    "             (102,102,156),\n",
    "             (190,153,153),\n",
    "             (153,153,153),\n",
    "             (250,170, 30),\n",
    "             (220,220,  0),\n",
    "             (107,142, 35),\n",
    "             (152,251,152),\n",
    "             ( 70,130,180),\n",
    "             (220, 20, 60),\n",
    "             (255,  0,  0),\n",
    "             (  0,  0,142),\n",
    "             (  0,  0, 70),\n",
    "             (  0, 60,100),\n",
    "             (  0, 80,100),\n",
    "             (  0,  0,230),\n",
    "             (119, 11, 32)]\n",
    "\n",
    "def input_transform(image):\n",
    "    image = image.astype(np.float32)[:, :, ::-1]\n",
    "    image = image / 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image\n",
    "\n",
    "def load_pretrained(model, pretrained):\n",
    "    pretrained_dict = torch.load(pretrained, map_location='cpu')\n",
    "    if 'state_dict' in pretrained_dict:\n",
    "        pretrained_dict = pretrained_dict['state_dict']\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
    "    msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
    "    logger.info('load_weights_start')\n",
    "    logger.info(msg)\n",
    "    logger.info('load_weights_done')\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict, strict = False)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def find_contours(mask):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def calculate_centroid(contour):\n",
    "    M = cv2.moments(contour)\n",
    "    if M['m00'] != 0:\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        return (cx, cy)\n",
    "    return None\n",
    "\n",
    "def is_centroid_in_road(centroid, road_mask):\n",
    "    if centroid is not None:\n",
    "        cx, cy = centroid\n",
    "        return road_mask[cy,cx]\n",
    "    return False\n",
    "\n",
    "    \n",
    "def process_image(file_path, model):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    sv_img = np.zeros_like(img).astype(np.uint8)\n",
    "    img = input_transform(img)\n",
    "    img = img.transpose((2, 0, 1)).copy()\n",
    "    img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "    \n",
    "    pred = model(img)\n",
    "    pred = F.interpolate(pred, size=img.size()[-2:], mode='bilinear', align_corners=True)\n",
    "    pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # 사람의 중심점이 도로위에 있는지 확인\n",
    "    road_mask = (pred == 3).astype(np.uint8)\n",
    "    pedestrian_mask = (pred == 9).astype(np.uint8)\n",
    "    \n",
    "    road_contours = find_contours(road_mask)\n",
    "    pedestrian_contours = find_contours(pedestrian_mask)\n",
    "    \n",
    "    for i, color in enumerate(color_map):\n",
    "        for j in range(3):\n",
    "            sv_img[:, :, j][pred == i] = color_map[i][j]\n",
    "            \n",
    "    person_on_road = False\n",
    "    for contour in pedestrian_contours:\n",
    "        centroid = calculate_centroid(contour)\n",
    "        if is_centroid_in_road(centroid, road_mask):\n",
    "            person_on_road = True\n",
    "            break\n",
    "    \n",
    "    text = f'Person on road: {person_on_road}'\n",
    "    \n",
    "    FONTSCALE = 1\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    THICKNESS = 2\n",
    "    COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "    \n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "    \n",
    "    x = (width - text_width) // 2\n",
    "    y = 40 + text_height\n",
    "    cv2.putText(sv_img, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "    \n",
    "    sv_img = Image.fromarray(sv_img)\n",
    "    \n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    sv_img.save(os.path.join(SAVE_DIR, FILE_NAME))\n",
    "def process_video(file_path, model):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    # out = cv2.VideoWriter(os.path.join(SAVE_DIR, os.path.splitext(FILE_NAME)[0] + '.avi'), fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "    out = cv2.VideoWriter(os.path.join(SAVE_DIR, FILE_NAME), fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        \n",
    "        sv_img = np.zeros_like(frame).astype(np.uint8)\n",
    "        img = input_transform(frame)\n",
    "        img = img.transpose((2, 0, 1)).copy()\n",
    "        img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "        \n",
    "        pred = model(img)\n",
    "        pred = F.interpolate(pred, size=img.size()[-2:], mode='bilinear', align_corners=True)\n",
    "        pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        road_mask = (pred == 3).astype(np.uint8)\n",
    "        pedestrian_mask = (pred == 9).astype(np.uint8)\n",
    "        \n",
    "        road_contours = find_contours(road_mask)\n",
    "        pedestrian_contours = find_contours(pedestrian_mask)\n",
    "        \n",
    "        for i, color in enumerate(color_map):\n",
    "            for j in range(3):\n",
    "                sv_img[:, :, j][pred == i] = color_map[i][j]\n",
    "                \n",
    "        person_on_road = False\n",
    "        for contour in pedestrian_contours:\n",
    "            centroid = calculate_centroid(contour)\n",
    "            if is_centroid_in_road(centroid, road_mask):\n",
    "                person_on_road = True\n",
    "                break\n",
    "        \n",
    "        text = f'Person on road: {person_on_road}'\n",
    "        \n",
    "        FONTSCALE = 1\n",
    "        FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        THICKNESS = 2\n",
    "        COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "        \n",
    "        (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "        \n",
    "        x = (width - text_width) // 2\n",
    "        y = 40 + text_height\n",
    "        cv2.putText(sv_img, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "        \n",
    "        sv_img = cv2.cvtColor(sv_img, cv2.COLOR_RGB2BGR)\n",
    "        out.write(sv_img)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "       \n",
    "is_cityscape = False\n",
    "model = models.pidnet.get_pred_model('pidnet-s', 19 if is_cityscape else 11)\n",
    "model = load_pretrained(model, 'weights/PIDNet_S_Camvid_Test.pt').cuda()\n",
    "model.eval()\n",
    "ext = os.path.splitext(FILE_PATH)[-1].lower()\n",
    "if ext in ['.png', '.jpg', '.jpeg']:\n",
    "    process_image(FILE_PATH, model)\n",
    "elif ext in ['.mp4', '.avi', '.mov']:\n",
    "    process_video(FILE_PATH, model)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-23 20:28:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mload_weights_start\u001b[0m\n",
      "\u001b[32m2024-05-23 20:28:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mLoaded 453 parameters!\u001b[0m\n",
      "\u001b[32m2024-05-23 20:28:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mload_weights_done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from loguru import logger\n",
    "import models\n",
    "import os\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "# 설정 값들\n",
    "FILE_PATH = 'samples/test.mp4'\n",
    "FILE_NAME = os.path.basename(FILE_PATH)\n",
    "SAVE_DIR = 'output/'\n",
    "FONTSCALE = 1\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "THICKNESS = 2\n",
    "BLUE_COLOR = (0, 0, 255)\n",
    "RED_COLOR = (255, 40, 40)\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "color_map = [\n",
    "    (128, 64, 128), (244, 35, 232), (70, 70, 70), (102, 102, 156), (190, 153, 153),\n",
    "    (153, 153, 153), (250, 170, 30), (220, 220, 0), (107, 142, 35), (152, 251, 152),\n",
    "    (70, 130, 180), (220, 20, 60), (255, 0, 0), (0, 0, 142), (0, 0, 70),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 230), (119, 11, 32)\n",
    "]\n",
    "\n",
    "def input_transform(image):\n",
    "    image = image.astype(np.float32)[:, :, ::-1]\n",
    "    image = image / 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image\n",
    "\n",
    "def load_pretrained(model, pretrained):\n",
    "    pretrained_dict = torch.load(pretrained, map_location='cpu')\n",
    "    if 'state_dict' in pretrained_dict:\n",
    "        pretrained_dict = pretrained_dict['state_dict']\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
    "    msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
    "    logger.info('load_weights_start')\n",
    "    logger.info(msg)\n",
    "    logger.info('load_weights_done')\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "def find_contours(mask):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def is_person_near_road(pedestrian_mask, road_mask, threshold=1):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated_road_mask = cv2.dilate(road_mask, kernel, iterations=threshold)\n",
    "    return np.any(np.logical_and(pedestrian_mask, dilated_road_mask))\n",
    "\n",
    "def process_image(file_path, model):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    sv_img = np.zeros_like(img).astype(np.uint8)\n",
    "    img = input_transform(img)\n",
    "    img = img.transpose((2, 0, 1)).copy()\n",
    "    img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "\n",
    "    pred = model(img)\n",
    "    pred = F.interpolate(pred, size=img.size()[-2:], mode='bilinear', align_corners=True)\n",
    "    pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "    road_mask = (pred == 3).astype(np.uint8)\n",
    "    pedestrian_mask = (pred == 9).astype(np.uint8)\n",
    "\n",
    "    for i, color in enumerate(color_map):\n",
    "        for j in range(3):\n",
    "            sv_img[:, :, j][pred == i] = color_map[i][j]\n",
    "\n",
    "    person_on_road = is_person_near_road(pedestrian_mask, road_mask)\n",
    "\n",
    "    text = f'Person on road: {person_on_road}'\n",
    "    COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "    x = (width - text_width) // 2\n",
    "    y = 40 + text_height\n",
    "    cv2.putText(sv_img, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    sv_img = Image.fromarray(sv_img)\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    sv_img.save(os.path.join(SAVE_DIR, FILE_NAME))\n",
    "\n",
    "def process_video(file_path, model):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(os.path.join(SAVE_DIR, os.path.splitext(FILE_NAME)[0] + '.avi'), fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        sv_img = np.zeros_like(frame).astype(np.uint8)\n",
    "        img = input_transform(frame)\n",
    "        img = img.transpose((2, 0, 1)).copy()\n",
    "        img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "\n",
    "        pred = model(img)\n",
    "        pred = F.interpolate(pred, size=img.size()[-2:], mode='bilinear', align_corners=True)\n",
    "        pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "        road_mask = (pred == 3).astype(np.uint8)\n",
    "        pedestrian_mask = (pred == 9).astype(np.uint8)\n",
    "\n",
    "        for i, color in enumerate(color_map):\n",
    "            if i ==4 or i==5:\n",
    "                for j in range(3):\n",
    "                    sv_img[:, :, j][pred == i] = color_map[i][j]\n",
    "\n",
    "        person_on_road = is_person_near_road(pedestrian_mask, road_mask)\n",
    "\n",
    "        text = f'Person on road: {person_on_road}'\n",
    "        COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "\n",
    "        (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "        x = (width - text_width) // 2\n",
    "        y = 40 + text_height\n",
    "        cv2.putText(sv_img, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "        sv_img = cv2.cvtColor(sv_img, cv2.COLOR_RGB2BGR)\n",
    "        out.write(sv_img)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "is_cityscape = False\n",
    "model = models.pidnet.get_pred_model('pidnet-s', 19 if is_cityscape else 11)\n",
    "model = load_pretrained(model, 'weights/PIDNet_S_Camvid_Test.pt').cuda()\n",
    "model.eval()\n",
    "\n",
    "ext = os.path.splitext(FILE_PATH)[-1].lower()\n",
    "if ext in ['.png', '.jpg', '.jpeg']:\n",
    "    process_image(FILE_PATH, model)\n",
    "elif ext in ['.mp4', '.avi', '.mov']:\n",
    "    process_video(FILE_PATH, model)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file format\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
