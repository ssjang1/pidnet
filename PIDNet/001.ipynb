{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-23 20:14:55.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload_weights_start\u001b[0m\n",
      "\u001b[32m2024-05-23 20:14:55.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mLoaded 453 parameters!\u001b[0m\n",
      "\u001b[32m2024-05-23 20:14:55.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mload_weights_done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "\n",
    "from loguru import logger\n",
    "import models\n",
    "\n",
    "FILE_PATH = 'samples/0001TP_009210.png'\n",
    "FILE_NAME = os.path.basename(FILE_PATH)\n",
    "SAVE_DIR = 'output/'\n",
    "FONTSCALE = 1\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "THICKNESS = 2\n",
    "BLUE_COLOR = (0,0,255)\n",
    "RED_COLOR = (255,40,40)\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "color_map = [(128, 64,128),\n",
    "             (244, 35,232),\n",
    "             ( 70, 70, 70),\n",
    "             (102,102,156),\n",
    "             (190,153,153),\n",
    "             (153,153,153),\n",
    "             (250,170, 30),\n",
    "             (220,220,  0),\n",
    "             (107,142, 35),\n",
    "             (152,251,152),\n",
    "             ( 70,130,180),\n",
    "             (220, 20, 60),\n",
    "             (255,  0,  0),\n",
    "             (  0,  0,142),\n",
    "             (  0,  0, 70),\n",
    "             (  0, 60,100),\n",
    "             (  0, 80,100),\n",
    "             (  0,  0,230),\n",
    "             (119, 11, 32)]\n",
    "\n",
    "def input_transform(image):\n",
    "    image = image.astype(np.float32)[:, :, ::-1]\n",
    "    image = image / 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image\n",
    "\n",
    "def load_pretrained(model, pretrained):\n",
    "    pretrained_dict = torch.load(pretrained, map_location='cpu')\n",
    "    if 'state_dict' in pretrained_dict:\n",
    "        pretrained_dict = pretrained_dict['state_dict']\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
    "    msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
    "    logger.info('load_weights_start')\n",
    "    logger.info(msg)\n",
    "    logger.info('load_weights_done')\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict, strict = False)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def find_contours(mask):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "def calculate_centroid(contour):\n",
    "    M = cv2.moments(contour)\n",
    "    if M['m00'] != 0:\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        return (cx, cy)\n",
    "    return None\n",
    "\n",
    "def is_centroid_in_road(centroid, road_mask):\n",
    "    if centroid is not None:\n",
    "        cx, cy = centroid\n",
    "        return road_mask[cy,cx]\n",
    "    return False\n",
    "\n",
    "    \n",
    "def process_image(file_path, model):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    sv_img = np.zeros_like(img).astype(np.uint8)\n",
    "    img = input_transform(img)\n",
    "    img = img.transpose((2, 0, 1)).copy()\n",
    "    img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "    \n",
    "    pred = model(img)\n",
    "    pred = F.interpolate(pred, size=img.size()[-2:], mode='bilinear', align_corners=True)\n",
    "    pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # 사람의 중심점이 도로위에 있는지 확인\n",
    "    road_mask = (pred == 3).astype(np.uint8)\n",
    "    pedestrian_mask = (pred == 9).astype(np.uint8)\n",
    "    \n",
    "    road_contours = find_contours(road_mask)\n",
    "    pedestrian_contours = find_contours(pedestrian_mask)\n",
    "    \n",
    "    for i, color in enumerate(color_map):\n",
    "        for j in range(3):\n",
    "            sv_img[:, :, j][pred == i] = color_map[i][j]\n",
    "            \n",
    "    person_on_road = False\n",
    "    for contour in pedestrian_contours:\n",
    "        centroid = calculate_centroid(contour)\n",
    "        if is_centroid_in_road(centroid, road_mask):\n",
    "            person_on_road = True\n",
    "            break\n",
    "    \n",
    "    text = f'Person on road: {person_on_road}'\n",
    "    \n",
    "    FONTSCALE = 1\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    THICKNESS = 2\n",
    "    COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "    \n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "    \n",
    "    x = (width - text_width) // 2\n",
    "    y = 40 + text_height\n",
    "    cv2.putText(sv_img, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "    \n",
    "    sv_img = Image.fromarray(sv_img)\n",
    "    \n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    sv_img.save(os.path.join(SAVE_DIR, FILE_NAME))\n",
    "def process_video(file_path, model):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    # out = cv2.VideoWriter(os.path.join(SAVE_DIR, os.path.splitext(FILE_NAME)[0] + '.avi'), fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "    out = cv2.VideoWriter(os.path.join(SAVE_DIR, FILE_NAME), fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        \n",
    "        sv_img = np.zeros_like(frame).astype(np.uint8)\n",
    "        img = input_transform(frame)\n",
    "        img = img.transpose((2, 0, 1)).copy()\n",
    "        img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "        \n",
    "        pred = model(img)\n",
    "        pred = F.interpolate(pred, size=img.size()[-2:], mode='bilinear', align_corners=True)\n",
    "        pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "        \n",
    "        road_mask = (pred == 3).astype(np.uint8)\n",
    "        pedestrian_mask = (pred == 9).astype(np.uint8)\n",
    "        \n",
    "        road_contours = find_contours(road_mask)\n",
    "        pedestrian_contours = find_contours(pedestrian_mask)\n",
    "        \n",
    "        for i, color in enumerate(color_map):\n",
    "            for j in range(3):\n",
    "                sv_img[:, :, j][pred == i] = color_map[i][j]\n",
    "                \n",
    "        person_on_road = False\n",
    "        for contour in pedestrian_contours:\n",
    "            centroid = calculate_centroid(contour)\n",
    "            if is_centroid_in_road(centroid, road_mask):\n",
    "                person_on_road = True\n",
    "                break\n",
    "        \n",
    "        text = f'Person on road: {person_on_road}'\n",
    "        \n",
    "        FONTSCALE = 1\n",
    "        FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        THICKNESS = 2\n",
    "        COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "        \n",
    "        (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "        \n",
    "        x = (width - text_width) // 2\n",
    "        y = 40 + text_height\n",
    "        cv2.putText(sv_img, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "        \n",
    "        sv_img = cv2.cvtColor(sv_img, cv2.COLOR_RGB2BGR)\n",
    "        out.write(sv_img)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "       \n",
    "is_cityscape = False\n",
    "model = models.pidnet.get_pred_model('pidnet-s', 19 if is_cityscape else 11)\n",
    "model = load_pretrained(model, 'weights/PIDNet_S_Camvid_Test.pt').cuda()\n",
    "model.eval()\n",
    "ext = os.path.splitext(FILE_PATH)[-1].lower()\n",
    "if ext in ['.png', '.jpg', '.jpeg']:\n",
    "    process_image(FILE_PATH, model)\n",
    "elif ext in ['.mp4', '.avi', '.mov']:\n",
    "    process_video(FILE_PATH, model)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, stride=32):\n",
    "    height, width = image.shape[:2]\n",
    "    pad_height = (stride - height % stride) % stride\n",
    "    pad_width = (stride - width % stride) % stride\n",
    "    padded_image = cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-24 17:25:48.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mload_weights_start\u001b[0m\n",
      "\u001b[32m2024-05-24 17:25:48.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mLoaded 453 parameters!\u001b[0m\n",
      "\u001b[32m2024-05-24 17:25:48.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_pretrained\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mload_weights_done\u001b[0m\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 22.8ms\n",
      "Speed: 0.0ms preprocess, 22.8ms inference, 3.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 20.5ms\n",
      "Speed: 0.0ms preprocess, 20.5ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 19.2ms\n",
      "Speed: 0.0ms preprocess, 19.2ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.9ms\n",
      "Speed: 0.0ms preprocess, 18.9ms inference, 2.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 22.9ms\n",
      "Speed: 0.0ms preprocess, 22.9ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 28.4ms\n",
      "Speed: 0.0ms preprocess, 28.4ms inference, 6.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 3.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 4.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 3.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 4.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 4.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 26.1ms\n",
      "Speed: 0.0ms preprocess, 26.1ms inference, 4.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.7ms\n",
      "Speed: 0.0ms preprocess, 18.7ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 6.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 4.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 6.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 5.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 3.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 3.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 3.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 3.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.9ms\n",
      "Speed: 0.0ms preprocess, 18.9ms inference, 4.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 3.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 3.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 3.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.1ms preprocess, 18.4ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 5.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 6.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.6ms\n",
      "Speed: 0.0ms preprocess, 18.6ms inference, 2.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 25.0ms\n",
      "Speed: 0.0ms preprocess, 25.0ms inference, 4.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 2.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 3.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.8ms\n",
      "Speed: 0.0ms preprocess, 18.8ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.6ms\n",
      "Speed: 0.2ms preprocess, 18.6ms inference, 4.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 6.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 5.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.9ms\n",
      "Speed: 0.0ms preprocess, 18.9ms inference, 3.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 4.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 3.2ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 23.9ms\n",
      "Speed: 0.0ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 3.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 26.2ms\n",
      "Speed: 0.0ms preprocess, 26.2ms inference, 4.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 5.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 2.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 2.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.3ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.1ms preprocess, 18.4ms inference, 3.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 4.0ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 5.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 2.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 4.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 3.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.2ms\n",
      "Speed: 0.0ms preprocess, 18.2ms inference, 3.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 2.7ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.8ms\n",
      "Speed: 0.0ms preprocess, 18.8ms inference, 3.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.3ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 3.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 2.8ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.8ms\n",
      "Speed: 0.0ms preprocess, 17.8ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 4.1ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 3.6ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 21.4ms\n",
      "Speed: 0.0ms preprocess, 21.4ms inference, 2.5ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 25.3ms\n",
      "Speed: 0.0ms preprocess, 25.3ms inference, 2.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 3.4ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.4ms\n",
      "Speed: 0.1ms preprocess, 18.4ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n",
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 2.6399998664855957. Dividing input by 255.\n",
      "0: 1088x1920 (no detections), 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 1088, 1920)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from loguru import logger\n",
    "import models\n",
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "# 설정 값들\n",
    "FILE_PATH = 'samples/test.mp4'\n",
    "# FILE_PATH = 'samples/test.png'\n",
    "FILE_NAME = os.path.basename(FILE_PATH)\n",
    "SAVE_DIR = 'output/'\n",
    "FONTSCALE = 1\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "THICKNESS = 2\n",
    "BLUE_COLOR = (0, 0, 255)\n",
    "RED_COLOR = (255, 40, 40)\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "color_map = [\n",
    "    (128, 64, 128), (244, 35, 232), (70, 70, 70), (102, 102, 156), (190, 153, 153),\n",
    "    (153, 153, 153), (250, 170, 30), (220, 220, 0), (107, 142, 35), (152, 251, 152),\n",
    "    (70, 130, 180), (220, 20, 60), (255, 0, 0), (0, 0, 142), (0, 0, 70),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 230), (119, 11, 32)\n",
    "]\n",
    "\n",
    "def input_transform(image):\n",
    "    image = image.astype(np.float32)[:, :, ::-1]\n",
    "    image = image / 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image\n",
    "\n",
    "def load_pretrained(model, pretrained):\n",
    "    pretrained_dict = torch.load(pretrained, map_location='cpu')\n",
    "    if 'state_dict' in pretrained_dict:\n",
    "        pretrained_dict = pretrained_dict['state_dict']\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
    "    msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
    "    logger.info('load_weights_start')\n",
    "    logger.info(msg)\n",
    "    logger.info('load_weights_done')\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "def find_contours(mask):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "# def is_person_near_road(pedestrian_mask, road_mask, threshold=1):\n",
    "#     kernel = np.ones((3, 3), np.uint8)\n",
    "#     dilated_road_mask = cv2.dilate(road_mask, kernel, iterations=threshold)\n",
    "#     return np.any(np.logical_and(pedestrian_mask, dilated_road_mask))\n",
    "\n",
    "def is_person_on_road(boxes, road_mask):\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box[:]\n",
    "        if np.any(road_mask[y1:y2, x1:x2]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def pad_image(image, stride=32):\n",
    "    height, width = image.shape[:2]\n",
    "    pad_height = (stride - height % stride) % stride\n",
    "    pad_width = (stride - width % stride) % stride\n",
    "    padded_image = cv2.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    return padded_image\n",
    "\n",
    "\n",
    "def process_image(file_path, model):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    height, width, _ = img.shape\n",
    "    padded_img = pad_image(img)\n",
    "    padded_height, padded_width, _ = padded_img.shape\n",
    "\n",
    "    sv_img = np.zeros_like(padded_img).astype(np.uint8)\n",
    "    img = input_transform(padded_img)\n",
    "    img = img.transpose((2, 0, 1)).copy()\n",
    "    img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "\n",
    "    pred = model(img)\n",
    "    pred = F.interpolate(pred, size=(padded_height, padded_width), mode='bilinear', align_corners=True)\n",
    "    pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "    pred = pred[:height, :width]  # 패딩된 부분을 제거하여 원본 크기로 되돌림\n",
    "\n",
    "    road_mask = (pred == 6).astype(np.uint8)\n",
    "    # pedestrian_mask = (pred == 5).astype(np.uint8)\n",
    "\n",
    "    for i, color in enumerate(color_map):\n",
    "        if i == 6 :\n",
    "            for j in range(3):\n",
    "                sv_img[:height, :width, j][pred == i] = color_map[i][j]  # 패딩된 부분을 제외한 원본 크기 부분에만 색 적용\n",
    "\n",
    "    # person_on_road = is_person_near_road(pedestrian_mask, road_mask)\n",
    "    person_on_road = is_person_on_road()\n",
    "    \n",
    "    \n",
    "    text = f'Person on road: {person_on_road}'\n",
    "    COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "    x = (width - text_width) // 2\n",
    "    y = 40 + text_height\n",
    "    cv2.putText(sv_img, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    sv_img = Image.fromarray(sv_img[:height, :width])  # 원본 크기로 다시 되돌림\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    sv_img.save(os.path.join(SAVE_DIR, FILE_NAME))\n",
    "\n",
    "def process_video(file_path, model, yolov8_model):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(os.path.join(SAVE_DIR, FILE_NAME), fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        padded_frame = pad_image(frame)\n",
    "        padded_height, padded_width, _ = padded_frame.shape\n",
    "\n",
    "        sv_img = np.zeros_like(padded_frame).astype(np.uint8)\n",
    "        img = input_transform(padded_frame)\n",
    "        img = img.transpose((2, 0, 1)).copy()\n",
    "        img = torch.from_numpy(img).unsqueeze(0).cuda()\n",
    "\n",
    "        pred = model(img)\n",
    "        pred = F.interpolate(pred, size=(padded_height, padded_width), mode='bilinear', align_corners=True)\n",
    "        pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()\n",
    "        pred = pred[:height, :width]  # 패딩된 부분을 제거하여 원본 크기로 되돌림\n",
    "\n",
    "        road_mask = (pred == 6).astype(np.uint8)\n",
    "        \n",
    "        boxes = yolov8_model(img, classes=0)[0].boxes.xyxy\n",
    "        \n",
    "        # pedestrian_mask = (pred == 5).astype(np.uint8)\n",
    "\n",
    "        # for i, color in enumerate(color_map):\n",
    "        #     if i == 6 :\n",
    "        #         for j in range(3):\n",
    "        #             sv_img[:height, :width, j][pred == i] = color_map[i][j]  # 패딩된 부분을 제외한 원본 크기 부분에만 색 적용\n",
    "\n",
    "        # person_on_road = is_person_near_road(pedestrian_mask, road_mask)\n",
    "        \n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box[:4].astype(int)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # 바운딩 박스 그리기\n",
    "            \n",
    "        person_on_road = is_person_on_road(boxes,road_mask)\n",
    "        \n",
    "        text = f'Person on road: {person_on_road}'\n",
    "        COLOR = BLUE_COLOR if person_on_road else RED_COLOR\n",
    "\n",
    "        (text_width, text_height), _ = cv2.getTextSize(text, FONT, FONTSCALE, THICKNESS)\n",
    "        x = (width - text_width) // 2\n",
    "        y = 40 + text_height\n",
    "        cv2.putText(frame, text, (x, y), FONT, FONTSCALE, COLOR, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame[:height, :width])  # 원본 크기로 다시 되돌림\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "is_cityscape = False\n",
    "model = models.pidnet.get_pred_model('pidnet-s', 19 if is_cityscape else 11)\n",
    "model = load_pretrained(model, 'weights/PIDNet_S_Camvid_Test.pt').cuda()\n",
    "model.eval()\n",
    "yolov8_model = YOLO('yolov8n.pt')\n",
    "\n",
    "\n",
    "ext = os.path.splitext(FILE_PATH)[-1].lower()\n",
    "if ext in ['.png', '.jpg', '.jpeg']:\n",
    "    process_image(FILE_PATH, model)\n",
    "elif ext in ['.mp4', '.avi', '.mov']:\n",
    "    process_video(FILE_PATH, model, yolov8_model)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/projects/seg/PIDNet/samples/test.png: 352x640 1 person, 33.0ms\n",
      "Speed: 2.9ms preprocess, 33.0ms inference, 2.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "yolov8_model = YOLO('yolov8n.pt')\n",
    "results = yolov8_model('samples/test.png',save=True,classes=0)\n",
    "\n",
    "boxes = results[0].boxes.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov8_model = YOLO('yolov8n.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
